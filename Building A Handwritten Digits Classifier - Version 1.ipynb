{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Handwritten Digits Classifier\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#loading\">Dataset Loading</a></li>\n",
    "<li><a href=\"#images\">Displaying the Images</a></li>\n",
    "<li><a href=\"#splitting\">Data Spliting</a></li>\n",
    "<li><a href=\"#nn\">Neural Networks</a></li>\n",
    "<li><a href=\"#lr\">Logistic Regression</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "In this project we will be using Multilayer Perceptron (Deep Neural Network) and Logistic Regression to analyse and classify a dataset of images representing handwritten digits from 0 to 9. \n",
    "- Data: copy of the hand-written digits dataset from UCI.\n",
    "- Metric: **accuracy**, as all digits are considered equally important.\n",
    "\n",
    "Note: This notebook is so basic for now, you may consider making modifications as: \n",
    "> Using a pipeline to try other machine learning models.\n",
    "> Applying different activation functions that may improve accuracies.\n",
    "> Tune the model parameters.\n",
    "> Increasing number of neurons and layers.\n",
    "> Adding use higher performance tools for neural networks (like Tensorflow or PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## Dataset Loading\n",
    "Scikit-learn contains a number of datasets pre-loaded with the library, within the namespace of sklearn.datasets. The load_digits() function returns a copy of the hand-written digits dataset from UCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data = load_digits(as_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data':       pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       " 0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       " 1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       " 2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       " 3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       " 4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       " 1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       " 1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       " 1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       " 1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       " \n",
       "       pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       " 0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       " 3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       " 4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " ...         ...        ...        ...        ...  ...        ...        ...   \n",
       " 1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       " 1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       " 1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       " 1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       " \n",
       "       pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       " 0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       " 1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       " 2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       " 3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       " 4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       " 1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       " 1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       " 1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       " 1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       " \n",
       "       pixel_7_6  pixel_7_7  \n",
       " 0           0.0        0.0  \n",
       " 1           0.0        0.0  \n",
       " 2           9.0        0.0  \n",
       " 3           0.0        0.0  \n",
       " 4           0.0        0.0  \n",
       " ...         ...        ...  \n",
       " 1792        0.0        0.0  \n",
       " 1793        0.0        0.0  \n",
       " 1794        0.0        0.0  \n",
       " 1795        0.0        0.0  \n",
       " 1796        1.0        0.0  \n",
       " \n",
       " [1797 rows x 64 columns],\n",
       " 'target': 0       0\n",
       " 1       1\n",
       " 2       2\n",
       " 3       3\n",
       " 4       4\n",
       "        ..\n",
       " 1792    9\n",
       " 1793    0\n",
       " 1794    8\n",
       " 1795    9\n",
       " 1796    8\n",
       " Name: target, Length: 1797, dtype: int32,\n",
       " 'frame':       pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       " 0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       " 1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       " 2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       " 3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       " 4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       " 1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       " 1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       " 1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       " 1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       " \n",
       "       pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       " 0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       " 4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " ...         ...        ...        ...        ...  ...        ...        ...   \n",
       " 1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       " 1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       " 1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       " \n",
       "       pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       " 0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       " 1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       " 2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       " 3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       " 4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       " ...         ...        ...        ...        ...        ...        ...   \n",
       " 1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       " 1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       " 1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       " 1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       " 1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       " \n",
       "       pixel_7_7  target  \n",
       " 0           0.0       0  \n",
       " 1           0.0       1  \n",
       " 2           0.0       2  \n",
       " 3           0.0       3  \n",
       " 4           0.0       4  \n",
       " ...         ...     ...  \n",
       " 1792        0.0       9  \n",
       " 1793        0.0       0  \n",
       " 1794        0.0       8  \n",
       " 1795        0.0       9  \n",
       " 1796        0.0       8  \n",
       " \n",
       " [1797 rows x 65 columns],\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = pd.DataFrame(data['data'])\n",
    "labels = pd.Series(data['target'])\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the features dataset is of 1797 rows.\n",
    "- Each **row** represent a grayscale image, showing a handwritten digit.\n",
    "\n",
    "We also have 64 columns\n",
    "- Each **column** represent the resolution of each image; 8 by 8, i.e. 64 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='images'></a>\n",
    "## Displaying some images from the data set.\n",
    "Images are of a very low resolution to reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select eight images (features) from the dataset\n",
    "sample = images.iloc[[0, 1, 2, 3, 4, 5, 6, 7], :]\n",
    "# plot them\n",
    "fig, axs = plt.subplots(2, 4, figsize=(10, 5))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = sample.iloc[i, :].values.reshape(8, 8)\n",
    "    ax.imshow(img, cmap='gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No data cleaning was performed as the data was already clean and ready to be used.\n",
    "\n",
    "Note: You'll notice data shuffling to break any patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='splitting'></a>\n",
    "## Splitting up the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 0, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nn'></a>\n",
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "train set: 0.5393180236604036\n",
      "test set: 0.5111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nn_model = MLPClassifier(hidden_layer_sizes = (2, ), activation = 'relu', solver = 'adam', random_state = 0)\n",
    "nn_model.fit(x_train, y_train)\n",
    "train_pred = nn_model.predict(x_train)\n",
    "test_pred = nn_model.predict(x_test)\n",
    "\n",
    "print('Accuracies:')\n",
    "print('train set:', accuracy_score(y_train, train_pred))\n",
    "print('test set:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105080</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712596</td>\n",
       "      <td>0.636111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.757829</td>\n",
       "      <td>0.705556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.894920</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.968685</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train      test\n",
       "3   0.105080  0.083333\n",
       "4   0.712596  0.636111\n",
       "6   0.757829  0.705556\n",
       "8   0.894920  0.841667\n",
       "10  0.968685  0.941667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons = [3, 4, 6, 8, 10]\n",
    "\n",
    "nn_train_accuracy = []\n",
    "nn_test_accuracy = []\n",
    "\n",
    "for i in neurons:\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes = (i, ), activation = 'relu', solver='adam', random_state = 0)\n",
    "    nn_model.fit(x_train, y_train)\n",
    "    \n",
    "    train_pred = nn_model.predict(x_train)\n",
    "    test_pred = nn_model.predict(x_test)\n",
    "    \n",
    "    nn_test_accuracy.append(accuracy_score(y_test, test_pred))\n",
    "    nn_train_accuracy.append(accuracy_score(y_train, train_pred))\n",
    "    \n",
    "nn_results = pd.DataFrame(zip(nn_train_accuracy, nn_test_accuracy), \n",
    "                           index=neurons, columns=['train', 'test'])\n",
    "nn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers on the left represents the number of neurons we used in each time creating the model.\n",
    "\n",
    "We can see here that the accuracy was improving as the number of neurons increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101713</td>\n",
       "      <td>0.101844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.737585</td>\n",
       "      <td>0.684475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.813998</td>\n",
       "      <td>0.746359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900574</td>\n",
       "      <td>0.837520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.978421</td>\n",
       "      <td>0.918731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train      test\n",
       "3   0.101713  0.101844\n",
       "4   0.737585  0.684475\n",
       "6   0.813998  0.746359\n",
       "8   0.900574  0.837520\n",
       "10  0.978421  0.918731"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "neurons = [3, 4, 6, 8, 10]\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for i in neurons:\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes = (i, ), activation = 'relu', random_state = 0)\n",
    "    cv_score = cross_validate(nn_model, images, labels,\n",
    "                          cv = 10,\n",
    "                          scoring = 'accuracy', return_train_score = True, )\n",
    "    train_acc = np.average(cv_score['train_score'])\n",
    "    test_acc = np.average(cv_score['test_score'])\n",
    "    \n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "\n",
    "results = pd.DataFrame(zip(train_accuracy, test_accuracy), \n",
    "                           index=neurons, columns=['train', 'test'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers on the left represents the number of neurons we used in each time creating the model.\n",
    "\n",
    "We can see here that the accuracy was improving as the number of neurons increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr'></a>\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies:\n",
      "train set: 1.0\n",
      "test set: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, solver='newton-cg', random_state = 0)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "pred_train = lr.predict(x_train)\n",
    "pred_test = lr.predict(x_test)\n",
    "\n",
    "print('Accuracies:')\n",
    "print('train set:', accuracy_score(y_train, pred_train))\n",
    "print('test set:', accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train    test\n",
       "0    1.0  0.9282"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_train_accuracy = []\n",
    "lr_test_accuracy = []\n",
    "\n",
    "lr_cv_score = cross_validate(lr, images, labels,\n",
    "                          cv = 10,\n",
    "                          scoring='accuracy', return_train_score = True)\n",
    "\n",
    "lr_train_acc = np.average(lr_cv_score['train_score'])\n",
    "lr_test_acc = np.average(lr_cv_score['test_score'])\n",
    "\n",
    "lr_train_accuracy.append(lr_train_acc)\n",
    "lr_test_accuracy.append(lr_test_acc)\n",
    "\n",
    "lr_results = pd.DataFrame(zip(lr_train_accuracy, lr_test_accuracy), columns=['train', 'test'])\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this notebook, I would like to say that it's intended for practicing some coding and trying new functions, but we can't really come up with conclusions without doing at least some of the modifications mentioned in the introduction. In other words, we can't say that model 1 is performing better than model 2 or vice versa depending on these results , this won't be right at this point. \n",
    "\n",
    "I will revisit this notebook soon for modifications and a conclusion."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
